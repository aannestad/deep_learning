{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b4cdbc7c3fa968f8f57a8da50a47c3ee9b8594a4de967130c021b1087ec3a6ed",
   "display_name": "Python 3.8.5 64-bit ('ml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "### Demonstrate batch training in pytorch\n",
    "\n",
    "Motivation: \n",
    "\n",
    "for epochs:\n",
    "    x,y = data -> forward + backward and update weights;\n",
    "\n",
    "however, gradient calculations on the entire data set is expensive if large.\n",
    "\n",
    "Solution:\n",
    "\n",
    "Divide data into smaller **batches**:\n",
    "\n",
    "    for epoch in epochs:\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = train ...\n",
    "\n",
    "Let samples = 100, batch_size = 20 -> 100/20 = 5 iterations pr. epoch\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader # for batch training\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First batch:\ntensor([[1.3050e+01, 1.6500e+00, 2.5500e+00, 1.8000e+01, 9.8000e+01, 2.4500e+00,\n         2.4300e+00, 2.9000e-01, 1.4400e+00, 4.2500e+00, 1.1200e+00, 2.5100e+00,\n         1.1050e+03],\n        [1.2690e+01, 1.5300e+00, 2.2600e+00, 2.0700e+01, 8.0000e+01, 1.3800e+00,\n         1.4600e+00, 5.8000e-01, 1.6200e+00, 3.0500e+00, 9.6000e-01, 2.0600e+00,\n         4.9500e+02],\n        [1.3070e+01, 1.5000e+00, 2.1000e+00, 1.5500e+01, 9.8000e+01, 2.4000e+00,\n         2.6400e+00, 2.8000e-01, 1.3700e+00, 3.7000e+00, 1.1800e+00, 2.6900e+00,\n         1.0200e+03],\n        [1.2370e+01, 1.1700e+00, 1.9200e+00, 1.9600e+01, 7.8000e+01, 2.1100e+00,\n         2.0000e+00, 2.7000e-01, 1.0400e+00, 4.6800e+00, 1.1200e+00, 3.4800e+00,\n         5.1000e+02]])\ntensor([[1.],\n        [2.],\n        [1.],\n        [2.]])\nTotal number of samples: 178\nBatch size: 4\nIterations pr. training loop: 45\n"
     ]
    }
   ],
   "source": [
    "# Store dataset in a class to unpack batches using torch.Dataloader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./my_data.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:,1:])\n",
    "        self.y = torch.from_numpy(xy[:,[0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "# Instantiate data class\n",
    "data = MyDataset()\n",
    "\n",
    "# torch.DataLoader takes dataset class and batch size\n",
    "dataloader = DataLoader(dataset=data, batch_size=4, shuffle=True)\n",
    "\n",
    "# iterator for unpacking data (using next)\n",
    "data_iterator = iter(dataloader)\n",
    "features, labels = data_iterator.next()\n",
    "\n",
    "# Display the current batch of 4 X-features and their 4 y-lables\n",
    "print(\"First batch:\")\n",
    "print(features)\n",
    "print(labels)\n",
    "\n",
    "# Display training setup\n",
    "num_epocs = 2\n",
    "batch_size = 4\n",
    "n_samples = len(data)\n",
    "m_iterations = math.ceil(n_samples/batch_size)\n",
    "\n",
    "print(\"Total number of samples:\", n_samples)\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"Iterations pr. training loop:\", m_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/2, iteration: 1/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 2/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 3/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 4/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 5/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 6/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 7/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 8/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 9/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 10/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 11/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 12/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 13/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 14/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 15/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 16/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 17/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 18/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 19/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 20/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 21/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 22/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 23/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 24/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 25/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 26/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 27/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 28/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 29/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 30/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 31/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 32/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 33/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 34/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 35/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 36/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 37/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 38/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 39/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 40/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 41/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 42/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 43/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 44/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 1/2, iteration: 45/45, (batch) inputs: torch.Size([2, 13])\n Done with epoch 1\nEpoch: 2/2, iteration: 1/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 2/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 3/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 4/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 5/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 6/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 7/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 8/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 9/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 10/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 11/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 12/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 13/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 14/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 15/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 16/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 17/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 18/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 19/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 20/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 21/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 22/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 23/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 24/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 25/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 26/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 27/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 28/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 29/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 30/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 31/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 32/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 33/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 34/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 35/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 36/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 37/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 38/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 39/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 40/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 41/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 42/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 43/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 44/45, (batch) inputs: torch.Size([4, 13])\nEpoch: 2/2, iteration: 45/45, (batch) inputs: torch.Size([2, 13])\n Done with epoch 2\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epocs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # For each iteration (45 total), process the current batch of 4 samples \n",
    "        # Print to show simulated training progress:\n",
    "        print(f'Epoch: {epoch+1}/{num_epocs}, iteration: {i+1}/{m_iterations}, (batch) inputs: {inputs.shape}')\n",
    "    print(f' Done with epoch {epoch+1}')\n",
    "\n",
    "# Note: batch size is 4 is seen in the size of inputs in each step"
   ]
  }
 ]
}
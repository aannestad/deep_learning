{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b4cdbc7c3fa968f8f57a8da50a47c3ee9b8594a4de967130c021b1087ec3a6ed",
   "display_name": "Python 3.8.5 64-bit ('ml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ander helena in love with demetrius lysander in love with hermia demetrius in love with hermia philostrate master of the revels to theseus quince the carpenter snug the joiner bottom the weaver flute the bellows mender snout the tinker starveling the tailor oberon king of the fairies titania queen of the fairies puck or robin goodfellow a fairy peaseblossom fairy cobweb fairy moth fairy mustardseed fairy pyramus thisbe wall moonshine lion characters in the interlude performed by the clowns other\n"
     ]
    }
   ],
   "source": [
    "# Preprocess a text file\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "f=open(\"shakespeare.txt\",encoding=\"utf8\")\n",
    "text=f.read()\n",
    "text=text.lower()\n",
    "words = re.split(r'\\W+', text)\n",
    "tbl = str.maketrans('','', string.punctuation)\n",
    "clean = [w.translate(tbl) for w in words]\n",
    "text = \" \".join(clean)\n",
    "\n",
    "print(text[500:1000]) # inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', 'è')\n"
     ]
    }
   ],
   "source": [
    "# Get characters from text\n",
    "\n",
    "chars = tuple(sorted(set(text)))\n",
    "char_int = dict([(c,i) for i,c in enumerate(chars)])\n",
    "int_char = dict(enumerate(chars)) # (Invert) model ints back to characters\n",
    "print(chars) # inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      " act \n"
     ]
    }
   ],
   "source": [
    "# 1. One-hot encoding with No dependencies\n",
    "\n",
    "one_hot_text = []\n",
    "n = len(chars)\n",
    "\n",
    "int_text = [char_int[char] for char in text]\n",
    "\n",
    "for i in int_text:\n",
    "    a_hot = [0]*n\n",
    "    a_hot[i] = 1\n",
    "    one_hot_text.append(a_hot)\n",
    "\n",
    "print(one_hot_text[:5]) # inspect\n",
    "print(text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 2. One-hot encoding with Sklearn and numpy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder as encoder\n",
    "from numpy import asarray\n",
    "\n",
    "listchars = [list(i) for i in list(text)]\n",
    "one_hot_text = encoder(sparse=False).fit_transform(listchars)\n",
    "\n",
    "print(one_hot_text[:5]) # inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 3. One-hot encoding with Pytorch one_hot\n",
    "\n",
    "import torch.nn.functional\n",
    "\n",
    "x=torch.tensor(list(char_int.values()))\n",
    "one_hot_text = torch.nn.functional.one_hot(torch.tensor(int_text))\n",
    "one_hot_text.cpu().detach().numpy()\n",
    "\n",
    "print(np.array(one_hot_text)[:5]) # inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 0. 0.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 4. One-hot encoding with Pytorch scatter\n",
    "\n",
    "batch_size = len(int_text)\n",
    "\n",
    "int_text_tensor = torch.tensor(int_text).view(batch_size,1)\n",
    "\n",
    "one_hot_text = torch.zeros(batch_size,len(chars))   # preallocate\n",
    "one_hot_text.scatter_(1,int_text_tensor,1)          # fill one hot\n",
    "\n",
    "print(np.array(one_hot_text)[:5]) # inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}